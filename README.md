# neuro-invasion-detector

Краткое README для проекта **neuro-invasion-detector** — трансформерной системы детекции атак по сетевому трафику.

---

## Описание

Проект содержит пайплайн для подготовки датасетов из CSV, обучения трансформерных моделей на окнах сетевых пакетов и последующего тестирования/прогона сохранённых моделей (включая "мегамодель" — ensemble из нескольких сохранённых моделей).

Цель: исследовать и детектировать аномалии/вторжения в сетевом трафике с помощью последовательностного моделирования (Transformer Encoder).

---

## Структура проекта

```
project/
- model_generator.py        # конструктор модели (get_model)
- test_model.py             # функции для тестирования одной модели
- replace_label_marks.py    # нормализация/замена меток в датасете
- use_model.py              # скрипт для прогона сохранённых моделей (mega model)
- df2018_to_2017.py         # преобразование формата CSV 2018 -> 2017
- global_test.py            # (доп.) скрипт для глобального тестирования (при наличии)
- dataset_transform.py      # функции подготовки датасета и DataLoader
- learning.py               # логика обучения модели (get_trainde_model)
- main.py                   # главный скрипт: формирование данных, обучение и тестирование
models/                     # директории сохранённых моделей (по файлам .pth)
files/                      # исходные CSV-файлы

pyproject.toml              # зависимости и метаданные проекта
README.md                   # этот файл
```

---

## Основные файлы и их назначение

* **main.py** — основной контроллер: читает CSV из `./files`, делит на train/test, формирует DataLoader (через `dataset_transform.get_dataset`), создаёт модель (`model_generator.get_model`), тренирует (`learning.get_trainde_model`) и сохраняет `transformer_model.pth` в соответствующую папку внутри `./models`. Затем запускает `test_model` для оценки на отложенной выборке.

* **model_generator.py** — фабрика модели, содержит реализацию трансформерной архитектуры (`NetworkTransformer`) и функцию `get_model(...)`.

* **learning.py** — обучение модели: оптимизатор, цикл эпох, метрики и сохранение контрольных точек при необходимости.

* **dataset_transform.py** — преобразования DataFrame, скейлинг, формирование скользящих окон, класс `TrafficDataset` и функция `get_dataset`.

* **test_model.py / test_mega_model (use_model.py)** — функции/скрипты для оценки точности отдельно обученной модели и для прогона ensemble-модели (mega model) по скользящим окнам.

* **df2018_to_2017.py, replace_label_marks.py** — вспомогательные трансформации формата данных и нормализация меток.

---

## Установка

Рекомендуется создать виртуальное окружение (venv/conda) и установить зависимости из `pyproject.toml`.

Пример (POSIX):

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -e .
# или вручную:
# pip install ipykernel matplotlib pandas scikit-learn torch torchmetrics tqdm
```

> В `pyproject.toml` указана минимальная версия Python `>=3.14` — убедитесь, что у вас подходящая версия Python или скорректируйте `pyproject.toml` под вашу среду.

---

## Быстрый старт — обучение моделей

1. Поместите CSV-файлы в папку `./files` (формат ожидается как в репозитории).
2. Отредактируйте пути `READ_DIR` и `SAVE_DIR` в `main.py`, если нужно.
3. Запустите обучение всех датасетов:

```bash
python main.py
```

`main.py` создаст директории в `./models/<имя_файла_без_.csv>` и сохранит `transformer_model.pth` и сопутствующие артефакты (scaler.pkl, encoder.pkl) в каждой папке.

---

## Быстрый старт — прогон обученной модели (mega model)

В `use_model.py` реализована логика создания `MegaModel` — загрузки нескольких сохранённых моделей и применения их к скользящим окнам. По умолчанию настройки путей:

* `files/` — CSV с тестовыми данными
* `models/` — папка с поддиректориями обученных моделей

Запуск:

```bash
python use_model.py
```

---

## Заметки по конфигурации и устройствам

* Код поддерживает CUDA (`device='cuda'`), Apple MPS (`torch.mps`) и CPU. В `main.py` и `use_model.py` присутствует выбор устройства через `torch.cuda.is_available()` / `torch.mps.is_available()`.
* Для больших батчей (`BATCH_SIZE = 1024`) рекомендуется запуск на GPU с достаточной видеопамятью — иначе уменьшите `BATCH_SIZE`.